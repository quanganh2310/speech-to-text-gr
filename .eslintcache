[{"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\reportWebVitals.js":"1","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\App.js":"2","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\index.js":"3","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\result-stream.js":"4","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\recognize-stream.js":"5","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\recognize-microphone.js":"6","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\format-stream.js":"7","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\speaker-stream.js":"8","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\util\\querystring.js":"9","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\webaudio-l16-stream.js":"10","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\writable-element-stream.js":"11","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\to-promise.js":"12","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\content-type.js":"13","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\util\\process-user-parameters.js":"14","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\components\\ModelDropdown.js":"15"},{"size":362,"mtime":1609599939708,"results":"16","hashOfConfig":"17"},{"size":6281,"mtime":1614529084210,"results":"18","hashOfConfig":"17"},{"size":500,"mtime":1614397174744,"results":"19","hashOfConfig":"17"},{"size":1717,"mtime":1614085623606,"results":"20","hashOfConfig":"17"},{"size":17591,"mtime":1614092055945,"results":"21","hashOfConfig":"17"},{"size":7642,"mtime":1614093984617,"results":"22","hashOfConfig":"17"},{"size":5224,"mtime":1614085623386,"results":"23","hashOfConfig":"17"},{"size":12132,"mtime":1614085623610,"results":"24","hashOfConfig":"17"},{"size":749,"mtime":1614088623645,"results":"25","hashOfConfig":"17"},{"size":7174,"mtime":1614085623679,"results":"26","hashOfConfig":"17"},{"size":2343,"mtime":1614085623694,"results":"27","hashOfConfig":"17"},{"size":778,"mtime":1614085623649,"results":"28","hashOfConfig":"17"},{"size":2105,"mtime":1614085623304,"results":"29","hashOfConfig":"17"},{"size":1641,"mtime":1614088623608,"results":"30","hashOfConfig":"17"},{"size":1687,"mtime":1614526620997,"results":"31","hashOfConfig":"17"},{"filePath":"32","messages":"33","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"34"},"fq9jch",{"filePath":"35","messages":"36","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"37","messages":"38","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"39"},{"filePath":"40","messages":"41","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":1,"source":"42","usedDeprecatedRules":"39"},{"filePath":"43","messages":"44","errorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":1,"source":null},{"filePath":"45","messages":"46","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":1,"source":"47","usedDeprecatedRules":"48"},{"filePath":"49","messages":"50","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":1,"source":"51","usedDeprecatedRules":"52"},{"filePath":"53","messages":"54","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":1,"source":"55","usedDeprecatedRules":"34"},{"filePath":"56","messages":"57","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":1,"source":null},{"filePath":"58","messages":"59","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":1,"source":"60"},{"filePath":"61","messages":"62","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":1,"source":"63","usedDeprecatedRules":"64"},{"filePath":"65","messages":"66","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":1,"source":"67"},{"filePath":"68","messages":"69","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":1,"source":null},{"filePath":"70","messages":"71","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"72","messages":"73","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\reportWebVitals.js",[],["74","75"],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\App.js",["76"],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\index.js",[],["77","78"],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\result-stream.js",["79"],"/**\n * Copyright 2014 IBM Corp. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n'use strict';\n\nvar { Transform } = require('readable-stream');\nvar util = require('util');\nvar clone = require('clone');\n\n/**\n * Object-Mode stream that pulls result objects from the results array\n *\n * Also copies the top-level result_index to the individual results as .index\n *\n * @constructor\n * @param {Object} options\n */\nfunction ResultStream(options) {\n  options = options || {};\n  options.objectMode = true;\n  Transform.call(this, options);\n}\nutil.inherits(ResultStream, Transform);\n\nResultStream.prototype._transform = function(data, encoding, next) {\n  // when speaker_labels is enabled, some messages won't have a results array\n  if (Array.isArray(data.results)) {\n    // usually there is exactly 1 result, but there can be 0 in some circumstances, and potentially more in future iterations\n    data.results.forEach(function(result) {\n      var cloned = clone(result);\n      cloned.index = data.result_index;\n      this.push(cloned);\n    }, this);\n  } else {\n    this.push(data);\n  }\n  next();\n};\n\nResultStream.prototype.promise = require('./to-promise');\n\nmodule.exports = ResultStream;\n","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\recognize-stream.js",["80","81","82"],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\recognize-microphone.js",["83"],"/**\n * Copyright 2015 IBM Corp. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n'use strict';\nvar getUserMedia = require('get-user-media-promise');\nvar MicrophoneStream = require('microphone-stream');\nvar RecognizeStream = require('./recognize-stream.js');\nvar L16 = require('./webaudio-l16-stream.js');\nvar FormatStream = require('./format-stream.js');\nvar assign = require('object.assign/polyfill')();\nvar WritableElementStream = require('./writable-element-stream');\nvar { Writable } = require('readable-stream');\nvar ResultStream = require('./result-stream');\nvar SpeakerStream = require('./speaker-stream');\n\nvar preservedMicStream;\nvar bitBucket = new Writable({\n  write: function(chunk, encoding, callback) {\n    // when the keepMicrophone option is enabled, unused audio data is sent here so that it isn't buffered by other streams.\n    callback();\n  },\n  objectMode: true, // can still accept strings/buffers\n  decodeStrings: false\n});\n\n/**\n * @module watson-speech/speech-to-text/recognize-microphone\n */\n\n/**\n * Create and return a RecognizeStream sourcing audio from the user's microphone\n *\n * @param {Object} options - Also passed to {RecognizeStream}, and {FormatStream} when applicable\n * @param {String} options.token - Auth Token for CF services - see https://github.com/watson-developer-cloud/node-sdk#authorization\n * @param {String} options.accessToken - IAM Access Token for RC services - see https://github.com/watson-developer-cloud/node-sdk#authorization\n * @param {String} [options.url='wss://stream.watsonplatform.net/speech-to-text/api'] - Base URL for a service instance\n * @param {Boolean} [options.format=true] - pipe the text through a FormatStream which performs light formatting. Also controls smart_formatting option unless explicitly set.\n * @param {Boolean} [options.keepMicrophone=false] - keeps an internal reference to the microphone stream to reuse in subsequent calls (prevents multiple permissions dialogs in firefox)\n * @param {String|DOMElement} [options.outputElement] pipe the text to a [WriteableElementStream](WritableElementStream.html) targeting the specified element. Also defaults objectMode to true to enable interim results.\n * @param {Boolean} [options.extractResults=false] pipe results through a ResultStream stream to simplify the objects. (Default behavior before v0.22) Requires objectMode.\n * @param {Boolean} [options.resultsBySpeaker=false] Pipe results through a SpeakerStream. Forces speaker_labels and objectMode to be true.\n * @param {MediaStream} [options.mediaStream] Optionally pass in an existing MediaStream\n *\n * @return {RecognizeStream|SpeakerStream|FormatStream|ResultStream}\n */\nmodule.exports = function recognizeMicrophone(options) {\n  if (!options || (!options.token && !options.accessToken)) {\n    throw new Error('WatsonSpeechToText: missing required parameter: opts.token (CF) or opts.accessToken (RC)');\n  }\n\n  // the WritableElementStream works best in objectMode\n  if (options.outputElement && options.objectMode !== false) {\n    options.objectMode = true;\n  }\n  // the ResultExtractor only works in objectMode\n  if (options.extractResults) {\n    options.objectMode = true;\n  }\n  // SpeakerStream requires objectMode and speakerLabels\n  if (options.resultsBySpeaker) {\n    options.objectMode = true;\n    options.speakerLabels = true;\n  }\n\n  // default format to true (capitals and periods)\n  // default smartFormatting to options.format value (dates, currency, etc.)\n  options.format = options.format !== false;\n  if (typeof options.smartFormatting === 'undefined') {\n    options.smartFormatting = options.format;\n  }\n\n  var rsOpts = assign(\n    {\n      contentType: 'audio/l16;rate=16000',\n      interimResults: true\n    },\n    options\n  );\n\n  var recognizeStream = new RecognizeStream(rsOpts);\n  var streams = [recognizeStream]; // collect all of the streams so that we can bundle up errors and send them to the last one\n\n  // set up the output first so that we have a place to emit errors\n  // if there's trouble with the input stream\n  var stream = recognizeStream;\n\n  var keepMic = options.keepMicrophone;\n  var micStream;\n  if (keepMic && preservedMicStream) {\n    preservedMicStream.unpipe(bitBucket);\n    micStream = preservedMicStream;\n  } else {\n    // create the MicrophoneStream synchronously to allow it to resume the context in Safari on iOS 11\n    micStream = new MicrophoneStream({\n      objectMode: true,\n      bufferSize: options.bufferSize\n    });\n    var pm = options.mediaStream ? Promise.resolve(options.mediaStream) : getUserMedia({ video: false, audio: { deviceId: { exact: '2239e3f7a19c1a81fc41b5a50dc98c65cbc518c2c933b3b645a15da9d23a1465' } } });\n    pm.then(function(mediaStream) {\n      micStream.setStream(mediaStream);\n      if (keepMic) {\n        preservedMicStream = micStream;\n      }\n    }).catch(function(err) {\n      stream.emit('error', err);\n      if (err.name === 'NotSupportedError') {\n        stream.end(); // end the stream\n      }\n    });\n  }\n\n  var l16Stream = new L16({ writableObjectMode: true });\n\n  micStream.pipe(l16Stream).pipe(recognizeStream);\n\n  streams.push(micStream, l16Stream);\n\n  /**\n   * unpipes the mic stream to prevent any more audio from being sent over the wire\n   * temporarily re-pipes it to the bitBucket (basically /dev/null)  becuse\n   * otherwise it will buffer the audio from in between calls and prepend it to the next one\n   *\n   * @private\n   */\n  function end() {\n    micStream.unpipe(l16Stream);\n    micStream.pipe(bitBucket);\n    l16Stream.end();\n  }\n  // trigger on both stop and end events:\n  // stop will not fire when a stream ends due to a timeout\n  // but when stop does fire, we want to honor it immediately\n  // end will always fire, but it may take a few moments after stop\n  if (keepMic) {\n    recognizeStream.on('end', end);\n    recognizeStream.on('stop', end);\n  } else {\n    recognizeStream.on('end', micStream.stop.bind(micStream));\n    recognizeStream.on('stop', micStream.stop.bind(micStream));\n  }\n\n  if (options.resultsBySpeaker) {\n    stream = stream.pipe(new SpeakerStream(options));\n    streams.push(stream);\n  }\n\n  if (options.format) {\n    stream = stream.pipe(new FormatStream(options));\n    streams.push(stream);\n  }\n\n  if (options.outputElement) {\n    // we don't want to return the WES, just send data to it\n    streams.push(stream.pipe(new WritableElementStream(options)));\n  }\n\n  if (options.extractResults) {\n    stream = stream.pipe(new ResultStream());\n    streams.push(stream);\n  }\n\n  // Capture errors from any stream except the last one and emit them on the last one\n  streams.forEach(function(prevStream) {\n    if (prevStream !== stream) {\n      prevStream.on('error', stream.emit.bind(stream, 'error'));\n    }\n  });\n\n  if (stream !== recognizeStream) {\n    // add a stop button to whatever the final stream ends up being\n    stream.stop = recognizeStream.stop.bind(recognizeStream);\n  }\n\n  // expose the original stream to for debugging (and to support the JSON tab on the STT demo)\n  stream.recognizeStream = recognizeStream;\n\n  return stream;\n};\n\nmodule.exports.isSupported = getUserMedia.isSupported;\n",["84","85"],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\format-stream.js",["86"],"'use strict';\n\nvar { Transform } = require('readable-stream');\nvar util = require('util');\nvar clone = require('clone');\nvar defaults = require('defaults');\n\n/**\n * Applies some basic formatting to transcriptions:\n *  - Capitalize the first word of each sentence\n *  - Add a period to the end\n *  - Fix any \"cruft\" in the transcription\n *  - etc.\n *\n *  May be used as either a Stream, or a standalone helper.\n *\n * @param {Object} opts\n * @param {String} [opts.model] - some models / languages need special handling\n * @param {String} [opts.hesitation=''] - what to put down for a \"hesitation\" event, also consider \\u2026 (ellipsis: ...)\n * @param {Boolean} [options.objectMode=false] - emit `result` objects instead of string Buffers for the `data` events.\n * @constructor\n */\nfunction FormatStream(opts) {\n  this.options = defaults(opts, {\n    model: '', // some models should have all spaces removed\n    hesitation: '',\n    decodeStrings: false // false = don't convert strings to buffers before passing to _write\n  });\n  Transform.call(this, this.options);\n\n  this.isJaCn = this.options.model.substring(0, 5) === 'ja-JP' || this.options.model.substring(0, 5) === 'zh-CN';\n  this._transform = this.options.objectMode ? this.transformObject : this.transformString;\n}\nutil.inherits(FormatStream, Transform);\n\nvar reHesitation = /%HESITATION ?/g; // https://console.bluemix.net/docs/services/speech-to-text/output.html#output - D_ is handled below\nvar reRepeatedCharacter = /([a-z])\\1{2,}/gi; // detect the same character repeated three or more times and remove it\nvar reDUnderscoreWords = /D_[^\\s]+/g; // replace D_(anything)\n\n/**\n * Formats one or more words, removing special symbols, junk, and spacing for some languages\n * @param {String} text\n * @param {Boolean} isFinal\n * @return {String}\n */\nFormatStream.prototype.clean = function clean(text) {\n  // clean out \"junk\"\n  text = text\n    .replace(reHesitation, this.options.hesitation ? this.options.hesitation.trim() + ' ' : this.options.hesitation)\n    .replace(reRepeatedCharacter, '')\n    .replace(reDUnderscoreWords, '');\n\n  // remove spaces for Japanese and Chinese\n  if (this.isJaCn) {\n    text = text.replace(/ /g, '');\n  }\n\n  return text.trim() + ' '; // we want exactly 1 space at the end\n};\n\n/**\n * Capitalizes the first word of a sentence\n * @param {String} text\n * @return {string}\n */\nFormatStream.prototype.capitalize = function capitalize(text) {\n  // capitalize first word, returns '' in the case of an empty word\n  return text.charAt(0).toUpperCase() + text.substring(1);\n};\n\n/**\n * Puts a period on the end of a sentence\n * @param {String} text\n * @return {string}\n */\nFormatStream.prototype.period = function period(text) {\n  text = text.trim();\n  // don't put a period down if the clean stage remove all of the text\n  if (!text) {\n    return ' ';\n  }\n  // just add a space if the sentence ends in an ellipse\n  if (text.substr(-1) === '\\u2026') {\n    return text + ' ';\n  }\n  return text + (this.isJaCn ? '。' : '. ');\n};\n\nFormatStream.prototype.transformString = function(chunk, encoding, next) {\n  this.push(this.formatString(chunk.toString()));\n  next();\n};\n\nFormatStream.prototype.transformObject = function formatResult(result, encoding, next) {\n  this.push(this.formatResult(result));\n  next();\n};\n\n/**\n * Formats a single string result.\n *\n * May be used outside of Node.js streams\n *\n * @param {String} str - text to format\n * @param {bool} [isInterim=false] - set to true to prevent adding a period to the end of the sentence\n * @return {String}\n */\nFormatStream.prototype.formatString = function(str, isInterim) {\n  str = this.capitalize(this.clean(str));\n  return isInterim ? str : this.period(str);\n};\n\n/**\n * Creates a new result with all transcriptions formatted\n *\n * May be used outside of Node.js streams\n *\n * @param {Object} data\n * @return {Object}\n */\nFormatStream.prototype.formatResult = function formatResult(data) {\n  data = clone(data);\n  if (Array.isArray(data.results)) {\n    data.results.forEach(function(result, i) {\n      // if there are multiple interim results (as produced by the speaker stream),\n      // treat the text as final in all but the last result\n      var textFinal = result.final || i !== data.results.length - 1;\n\n      result.alternatives = result.alternatives.map(function(alt) {\n        alt.transcript = this.formatString(alt.transcript, !textFinal);\n        if (alt.timestamps) {\n          alt.timestamps = alt.timestamps\n            .map(function(ts, j, arr) {\n              // timestamps is an array of arrays, each sub-array is in the form [\"word\", startTime, endTime]'\n              ts[0] = this.clean(ts[0]);\n              if (j === 0) {\n                ts[0] = this.capitalize(ts[0]);\n              }\n\n              if (j === arr.length - 1 && textFinal) {\n                ts[0] = this.period(ts[0]);\n              }\n              return ts;\n            }, this)\n            .filter(function(ts) {\n              return ts[0]; // remove any timestamps without a word (due to cleaning out junk words)\n            });\n        }\n        return alt;\n      }, this);\n    }, this);\n  }\n  return data;\n};\n\nFormatStream.prototype.promise = require('./to-promise');\n\nmodule.exports = FormatStream;\n",["87","88"],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\speaker-stream.js",["89"],"/**\n * Copyright 2014 IBM Corp. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n'use strict';\n\nvar { Transform } = require('readable-stream');\nvar util = require('util');\nvar pullAllWith = require('lodash.pullallwith');\nvar noTimestamps = require('./no-timestamps');\nvar clone = require('clone');\n\n/**\n * Object-Mode stream that splits up results by speaker.\n *\n * Output format is similar to existing results formats, but with an extra speaker field,\n *\n * Output results array will usually contain multiple results.\n * All results are interim until the final batch; the text may change (if options.speakerlessInterim is enabled) or move from one interim result to another.\n *\n * Keywords, words_alternatives, and other features may appear on results that come slightly earlier than the timestamp due to the way things are split up.\n *\n * Ignores interim results from the service unless options.speakerlessInterim is enabled.\n *\n * @constructor\n * @param {Object} options\n * @param {boolean} [options.speakerlessInterim=false] - emit interim results before initial speaker has been identified (allows UI to update more quickly)\n */\nfunction SpeakerStream(options) {\n  options = options || {};\n  options.objectMode = true;\n  this.options = options;\n  Transform.call(this, options);\n  /**\n   * timestamps is a 2-d array.\n   * The sub-array is [word, from time, to time]\n   * Example:\n   * [\n       [\"Yes\", 28.92, 29.17],\n       [\"that's\", 29.17, 29.37],\n       [\"right\", 29.37, 29.64]\n    ]\n   * @type {Array<Array>}\n   * @private\n   */\n  this.results = [];\n  /**\n   * speaker_labels is an array of objects.\n   * Example:\n   * [{\n      \"from\": 28.92,\n      \"to\": 29.17,\n      \"speaker\": 1,\n      \"confidence\": 0.641,\n      \"final\": false\n    }, {\n      \"from\": 29.17,\n      \"to\": 29.37,\n      \"speaker\": 1,\n      \"confidence\": 0.641,\n      \"final\": false\n    }, {\n      \"from\": 29.37,\n      \"to\": 29.64,\n      \"speaker\": 1,\n      \"confidence\": 0.641,\n      \"final\": false\n    }]\n   * @type {Array<Object>}\n   * @private\n   */\n  this.speaker_labels = [];\n\n  this.mismatchErrorEmitted = false;\n\n  // flag to signal that labels were recieved before results, and therefore\n  // the stream needs to emit on the next batch of final results\n  this.extraLabels = false;\n}\nutil.inherits(SpeakerStream, Transform);\n\nSpeakerStream.prototype.isFinal = function() {\n  return this.speaker_labels.length && this.speaker_labels[this.speaker_labels.length - 1].final;\n};\n\n// positions in the timestamps 2d array\nvar WORD = 0;\nvar FROM = 1;\nvar TO = 2;\n\nSpeakerStream.ERROR_MISMATCH = 'MISMATCH';\n\n/**\n * Builds a results object with everything we've got so far\n * @return {*}\n */\nSpeakerStream.prototype.buildMessage = function() {\n  var final = this.isFinal();\n  this.extraLabels = false;\n\n  // first match all speaker_labeles to the appropriate word and result\n  // assumes that each speaker_label will have a matching word timestamp at the same index\n  // stops processing and emits an error if this assumption is violated\n  var resultIndex = 0;\n  var timestampIndex = -1;\n  var words = this.speaker_labels.map(\n    // eslint-disable-next-line camelcase\n    function(speaker_label) {\n      var result = this.results[resultIndex];\n      timestampIndex++;\n      var timestamp = result.alternatives[0].timestamps[timestampIndex];\n      if (!timestamp) {\n        timestampIndex = 0;\n        resultIndex++;\n        result = this.results[resultIndex];\n        timestamp = result && result.alternatives[0].timestamps[timestampIndex];\n      }\n      if (!timestamp) {\n        // this shouldn't happen normally, but the TimingStream could inadvertently cause a\n        // speaker_labels to be emitted before a result\n        this.extraLabels = true;\n        return null;\n      }\n      if (timestamp[FROM] !== speaker_label.from || timestamp[TO] !== speaker_label.to) {\n        if (!this.mismatchErrorEmitted) {\n          var err = new Error('Mismatch between speaker_label and word timestamp');\n          err.name = SpeakerStream.ERROR_MISMATCH;\n          // eslint-disable-next-line camelcase\n          err.speaker_label = speaker_label;\n          err.timestamp = timestamp;\n          // eslint-disable-next-line camelcase\n          err.speaker_labels = this.speaker_labels;\n          err.results = this.results;\n          this.emit('error', err);\n          this.mismatchErrorEmitted = true; // If one is off, then a bunch probably are. Just emit one error.\n        }\n        return null;\n      }\n      return {\n        timestamp: timestamp,\n        speaker: speaker_label.speaker,\n        result: result\n      };\n    },\n    this\n  );\n\n  // assume that there's nothing new to emit right now,\n  // wait for new results to match our new labels\n  if (this.extraLabels) {\n    return;\n  }\n\n  // filter out any nulls\n  words = words.filter(function(w) {\n    return w;\n  });\n\n  // group the words together into utterances by speaker\n  var utterances = words.reduce(function(arr, word) {\n    var utterance = arr[arr.length - 1];\n    // any time the speaker changes or the (original) result changes, create a new utterance\n    if (!utterance || utterance.speaker !== word.speaker || utterance.result !== word.result) {\n      utterance = {\n        speaker: word.speaker,\n        timestamps: [word.timestamp],\n        result: word.result\n      };\n      // and add it to the list\n      arr.push(utterance);\n    } else {\n      // otherwise just append the current word to the current result\n      utterance.timestamps.push(word.timestamp);\n    }\n    return arr;\n  }, []);\n\n  // create new results\n  var results = utterances.map(function(utterance, i) {\n    // if this is the first usage of this result, clone the original (to keep keywords and such)\n    // otherwise create a new one\n    var result;\n    var lastUtterance = utterances[i - 1] || {};\n    if (utterance.result === lastUtterance.result) {\n      result = { alternatives: [{}] };\n    } else {\n      result = clone(utterance.result);\n    }\n\n    // update the result object\n    // set the speaker\n    result.speaker = utterance.speaker;\n    // overwrite the transcript and timestamps on the first alternative\n    var alt = result.alternatives[0];\n    alt.transcript =\n      utterance.timestamps\n        .map(function(ts) {\n          return ts[WORD];\n        })\n        .join(' ') + ' ';\n    alt.timestamps = utterance.timestamps;\n    // overwrite the final value\n    result.final = final;\n\n    var start = utterance.timestamps[0][1];\n    var end = utterance.timestamps[utterance.timestamps.length - 1][2];\n\n    // overwrite the word_alternatives\n    if (utterance.result.word_alternatives) {\n      var alts = utterance.result.word_alternatives.filter(function(walt) {\n        return walt.start_time >= start && walt.end_time <= end;\n      });\n      result.word_alternatives = alts;\n    }\n\n    // overwrite the keywords spotted\n    /* eslint-disable camelcase */\n    var original_keywords_result = utterance.result.keywords_result;\n    if (original_keywords_result) {\n      var keywords_result = {};\n      Object.keys(original_keywords_result).forEach(function(keyword) {\n        var spottings = original_keywords_result[keyword].filter(function(spotting) {\n          return spotting.start_time >= start && spotting.end_time <= end;\n        });\n        if (spottings.length) {\n          keywords_result[keyword] = spottings;\n        }\n      });\n      result.keywords_result = keywords_result;\n    }\n    /* eslint-enable camelcase */\n\n    return result;\n  });\n\n  // result_index is always 0 because the results always includes the entire conversation so far.\n  return { results: results, result_index: 0 };\n};\n\n/**\n * Captures the timestamps out of results or errors if timestamps are missing\n * @param {Object} data\n */\nSpeakerStream.prototype.handleResults = function(data) {\n  if (noTimestamps(data)) {\n    var err = new Error('SpeakerStream requires that timestamps and speaker_labels be enabled');\n    err.name = noTimestamps.ERROR_NO_TIMESTAMPS;\n    this.emit('error', err);\n    return;\n  }\n  data.results\n    .filter(function(result) {\n      return result.final;\n    })\n    .forEach(function(result) {\n      this.results.push(result);\n    }, this);\n};\n\n// sorts by start time and then end time\nSpeakerStream.speakerLabelsSorter = function(a, b) {\n  if (a.from === b.from) {\n    if (a.to === b.to) {\n      return 0;\n    }\n    return a.to < b.to ? -1 : 1;\n  }\n  return a.from < b.from ? -1 : 1;\n};\n\n/**\n * Only the very last labeled word gets final: true. Up until that point, all speaker_labels are considered interim and\n * may be repeated with a new speaker selected in a later set of speaker_labels.\n *\n * @private\n * @param {Object} data\n */\nSpeakerStream.prototype.handleSpeakerLabels = function(data) {\n  var speaker_labels = data.speaker_labels; // eslint-disable-line camelcase\n\n  // remove any values from the old speaker_labels that are duplicated in the new set\n  pullAllWith(this.speaker_labels, speaker_labels, function(old, nw) {\n    return old.from === nw.from && old.to === nw.to;\n  });\n\n  // next append the new labels to the remaining old ones\n  this.speaker_labels.push.apply(this.speaker_labels, data.speaker_labels);\n\n  // finally, ensure the list is still sorted chronologically\n  this.speaker_labels.sort(SpeakerStream.speakerLabelsSorter);\n};\n\nSpeakerStream.prototype._transform = function(data, encoding, next) {\n  var message;\n  if (Array.isArray(data.results)) {\n    this.handleResults(data);\n    if (this.options.speakerlessInterim && data.results.length && data.results[0].final === false) {\n      message = this.buildMessage();\n      message.results = message.results.concat(data.results);\n    }\n    // clean up if things got out of order\n    if (this.extraLabels && data.results.length && data.results[0].final === true) {\n      message = this.buildMessage();\n    }\n  }\n  if (Array.isArray(data.speaker_labels)) {\n    this.handleSpeakerLabels(data);\n    message = this.buildMessage();\n  }\n  if (message) {\n    /**\n     * Emit an object similar to the normal results object, only with multiple entries in the results Array (a new one\n     * each time the speaker changes), and with a speaker field on the results.\n     *\n     * result_index is always 0 because the results always includes the entire conversation so far.\n     *\n     * @event SpeakerStream#data\n     * @param {Object} results-format message with multiple results and an extra speaker field on each result\n     */\n    this.push(message);\n  }\n  next();\n};\n\n/**\n * catches cases where speaker_labels was not enabled and internal errors that cause data loss\n *\n * @param {Function} done\n * @private\n */\nSpeakerStream.prototype._flush = function(done) {\n  var timestamps = this.results\n    .map(function(r) {\n      return r.alternatives[0].timestamps;\n    })\n    .reduce(function(a, b) {\n      return a.concat(b);\n    }, []);\n  if (timestamps.length !== this.speaker_labels.length) {\n    var msg;\n    if (timestamps.length && !this.speaker_labels.length) {\n      msg = 'No speaker_labels found. SpeakerStream requires speaker_labels to be enabled.';\n    } else {\n      msg =\n        'Mismatch between number of word timestamps (' +\n        timestamps.length +\n        ') and number of speaker_labels (' +\n        this.speaker_labels.length +\n        ') - some data may be lost.';\n    }\n    var err = new Error(msg);\n    err.name = SpeakerStream.ERROR_MISMATCH;\n    err.speaker_labels = this.speaker_labels;\n    err.results = this.results;\n    this.emit('error', err);\n  }\n  done();\n};\n\nSpeakerStream.prototype.promise = require('./to-promise');\n\nmodule.exports = SpeakerStream;\n","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\util\\querystring.js",["90"],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\webaudio-l16-stream.js",["91"],"'use strict';\n\nvar { Transform } = require('readable-stream');\nvar util = require('util');\nvar defaults = require('defaults');\n// some versions of the buffer browser lib don't support Buffer.from (such as the one included by the current version of express-browserify)\nvar bufferFrom = require('buffer-from');\n\nvar TARGET_SAMPLE_RATE = 16000;\n/**\n * Transforms Buffers or AudioBuffers into a binary stream of l16 (raw wav) audio, downsampling in the process.\n *\n * The watson speech-to-text service works on 16kHz and internally downsamples audio received at higher samplerates.\n * WebAudio is usually 44.1kHz or 48kHz, so downsampling here reduces bandwidth usage by ~2/3.\n *\n * Format event + stream can be combined with https://www.npmjs.com/package/wav to generate a wav file with a proper header\n *\n * Todo: support multi-channel audio (for use with <audio>/<video> elements) - will require interleaving audio channels\n *\n * @param {Object} options\n * @constructor\n */\nfunction WebAudioL16Stream(options) {\n  options = this.options = defaults(options, {\n    sourceSampleRate: 48000,\n    downsample: true\n  });\n\n  Transform.call(this, options);\n\n  this.bufferUnusedSamples = [];\n\n  if (options.objectMode || options.writableObjectMode) {\n    this._transform = this.handleFirstAudioBuffer;\n  } else {\n    this._transform = this.transformBuffer;\n    process.nextTick(this.emitFormat.bind(this));\n  }\n}\nutil.inherits(WebAudioL16Stream, Transform);\n\nWebAudioL16Stream.prototype.emitFormat = function emitFormat() {\n  this.emit('format', {\n    channels: 1,\n    bitDepth: 16,\n    sampleRate: this.options.downsample ? TARGET_SAMPLE_RATE : this.options.sourceSampleRate,\n    signed: true,\n    float: false\n  });\n};\n\n/**\n * Downsamples WebAudio to 16 kHz.\n *\n * Browsers can downsample WebAudio natively with OfflineAudioContext's but it was designed for non-streaming use and\n * requires a new context for each AudioBuffer. Firefox can handle this, but chrome (v47) crashes after a few minutes.\n * So, we'll do it in JS for now.\n *\n * This really belongs in it's own stream, but there's no way to create new AudioBuffer instances from JS, so its\n * fairly coupled to the wav conversion code.\n *\n * @param  {AudioBuffer} bufferNewSamples Microphone/MediaElement audio chunk\n * @return {Float32Array} 'audio/l16' chunk\n */\nWebAudioL16Stream.prototype.downsample = function downsample(bufferNewSamples) {\n  var buffer = null;\n  var newSamples = bufferNewSamples.length;\n  var unusedSamples = this.bufferUnusedSamples.length;\n  var i;\n  var offset;\n\n  if (unusedSamples > 0) {\n    buffer = new Float32Array(unusedSamples + newSamples);\n    for (i = 0; i < unusedSamples; ++i) {\n      buffer[i] = this.bufferUnusedSamples[i];\n    }\n    for (i = 0; i < newSamples; ++i) {\n      buffer[unusedSamples + i] = bufferNewSamples[i];\n    }\n  } else {\n    buffer = bufferNewSamples;\n  }\n\n  // Downsampling and low-pass filter:\n  // Input audio is typically 44.1kHz or 48kHz, this downsamples it to 16kHz.\n  // It uses a FIR (finite impulse response) Filter to remove (or, at least attinuate)\n  // audio frequencies > ~8kHz because sampled audio cannot accurately represent\n  // frequiencies greater than half of the sample rate.\n  // (Human voice tops out at < 4kHz, so nothing important is lost for transcription.)\n  // See http://dsp.stackexchange.com/a/37475/26392 for a good explination of this code.\n  var filter = [\n    -0.037935,\n    -0.00089024,\n    0.040173,\n    0.019989,\n    0.0047792,\n    -0.058675,\n    -0.056487,\n    -0.0040653,\n    0.14527,\n    0.26927,\n    0.33913,\n    0.26927,\n    0.14527,\n    -0.0040653,\n    -0.056487,\n    -0.058675,\n    0.0047792,\n    0.019989,\n    0.040173,\n    -0.00089024,\n    -0.037935\n  ];\n  var samplingRateRatio = this.options.sourceSampleRate / TARGET_SAMPLE_RATE;\n  var nOutputSamples = Math.floor((buffer.length - filter.length) / samplingRateRatio) + 1;\n  var outputBuffer = new Float32Array(nOutputSamples);\n\n  for (i = 0; i < outputBuffer.length; i++) {\n    offset = Math.round(samplingRateRatio * i);\n    var sample = 0;\n    for (var j = 0; j < filter.length; ++j) {\n      sample += buffer[offset + j] * filter[j];\n    }\n    outputBuffer[i] = sample;\n  }\n\n  var indexSampleAfterLastUsed = Math.round(samplingRateRatio * i);\n  var remaining = buffer.length - indexSampleAfterLastUsed;\n  if (remaining > 0) {\n    this.bufferUnusedSamples = new Float32Array(remaining);\n    for (i = 0; i < remaining; ++i) {\n      this.bufferUnusedSamples[i] = buffer[indexSampleAfterLastUsed + i];\n    }\n  } else {\n    this.bufferUnusedSamples = new Float32Array(0);\n  }\n\n  return outputBuffer;\n};\n\n/**\n * Accepts a Float32Array of audio data and converts it to a Buffer of l16 audio data (raw wav)\n *\n * Explanation for the math: The raw values captured from the Web Audio API are\n * in 32-bit Floating Point, between -1 and 1 (per the specification).\n * The values for 16-bit PCM range between -32768 and +32767 (16-bit signed integer).\n * Filter & combine samples to reduce frequency, then multiply to by 0x7FFF (32767) to convert.\n * Store in little endian.\n *\n * @param {Float32Array} input\n * @return {Buffer}\n */\nWebAudioL16Stream.prototype.floatTo16BitPCM = function(input) {\n  var output = new DataView(new ArrayBuffer(input.length * 2)); // length is in bytes (8-bit), so *2 to get 16-bit length\n  for (var i = 0; i < input.length; i++) {\n    var multiplier = input[i] < 0 ? 0x8000 : 0x7fff; // 16-bit signed range is -32768 to 32767\n    output.setInt16(i * 2, (input[i] * multiplier) | 0, true); // index, value (\"| 0\" = convert to 32-bit int, round towards 0), littleEndian.\n  }\n  return bufferFrom(output.buffer);\n};\n\n/**\n * Does some one-time setup to grab sampleRate and emit format, then sets _transform to the actual audio buffer handler and calls it.\n * @param {AudioBuffer} audioBuffer\n * @param {String} encoding\n * @param {Function} next\n */\nWebAudioL16Stream.prototype.handleFirstAudioBuffer = function handleFirstAudioBuffer(audioBuffer, encoding, next) {\n  this.options.sourceSampleRate = audioBuffer.sampleRate;\n  this.emitFormat();\n  this._transform = this.transformAudioBuffer;\n  this._transform(audioBuffer, encoding, next);\n};\n\n/**\n * Accepts an AudioBuffer (for objectMode), then downsamples to 16000 and converts to a 16-bit pcm\n *\n * @param {AudioBuffer} audioBuffer\n * @param {String} encoding\n * @param {Function} next\n */\nWebAudioL16Stream.prototype.transformAudioBuffer = function(audioBuffer, encoding, next) {\n  var source = audioBuffer.getChannelData(0);\n  if (this.options.downsample) {\n    source = this.downsample(source);\n  }\n  this.push(this.floatTo16BitPCM(source));\n  next();\n};\n\n/**\n * Accepts a Buffer (for binary mode), then downsamples to 16000 and converts to a 16-bit pcm\n *\n * @param {Buffer} nodebuffer\n * @param {String} encoding\n * @param {Function} next\n */\nWebAudioL16Stream.prototype.transformBuffer = function(nodebuffer, encoding, next) {\n  var source = new Float32Array(nodebuffer.buffer);\n  if (this.options.downsample) {\n    source = this.downsample(source);\n  }\n  this.push(this.floatTo16BitPCM(source));\n  next();\n};\n// new Float32Array(nodebuffer.buffer)\n\nmodule.exports = WebAudioL16Stream;\n","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\writable-element-stream.js",["92"],"'use strict';\n\nvar { Writable } = require('readable-stream');\nvar util = require('util');\nvar defaults = require('defaults');\n\n/**\n * Writable stream that accepts results in either object or string mode and outputs the text to a supplied html element\n *\n * Can show interim results when in objectMode\n *\n * @param {Object} options\n * @param {String|DOMElement} options.outputElement\n * @param {String} [options.property] what property of the element should the text be set to. Defaults to `value` for `<input>`s and `<textarea>`s, `textContent` for everything else\n * @param {Boolean} [options.clear=true] delete any previous text\n * @constructor\n */\nfunction WritableElementStream(options) {\n  this.options = options = defaults(options, {\n    decodeStrings: false, // false = don't convert strings to buffers before passing to _write (only applies in string mode)\n    property: null,\n    clear: true\n  });\n\n  this.el = typeof options.outputElement === 'string' ? document.querySelector(options.outputElement) : options.outputElement;\n\n  if (!this.el) {\n    throw new Error('Watson Speech to Text WritableElementStream: missing outputElement');\n  }\n\n  Writable.call(this, options);\n\n  // for most elements we set the textContent, but for form elements, the value property is probably the expected target\n  var propMap = {\n    INPUT: 'value',\n    TEXTAREA: 'value'\n  };\n  this.prop = options.property || propMap[this.el.nodeName] || 'textContent';\n\n  if (options.clear) {\n    this.el[this.prop] = '';\n  }\n\n  if (options.objectMode) {\n    this.finalizedText = this.el[this.prop];\n    this._write = this.writeObject;\n  } else {\n    this._write = this.writeString;\n  }\n}\nutil.inherits(WritableElementStream, Writable);\n\nWritableElementStream.prototype.writeString = function writeString(text, encoding, next) {\n  this.el[this.prop] += text;\n  next();\n};\n\nWritableElementStream.prototype.writeObject = function writeObject(data, encoding, next) {\n  if (Array.isArray(data.results)) {\n    data.results.forEach(function(result) {\n      if (result.final) {\n        this.finalizedText += result.alternatives[0].transcript;\n        this.el[this.prop] = this.finalizedText;\n      } else {\n        this.el[this.prop] = this.finalizedText + result.alternatives[0].transcript;\n      }\n    }, this);\n  }\n  next();\n};\n\nmodule.exports = WritableElementStream;\n",["93","94"],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\to-promise.js",["95"],"'use strict';\n\n/**\n * Helper method that can be bound to a stream - it sets the output to utf-8, captures all of the results, and returns a promise that resolves to the final text.\n * Essentially a smaller version of concat-stream wrapped in a promise\n *\n * @param {Stream} [stream=] optional stream param for when not bound to an existing stream instance\n * @return {Promise}\n */\nmodule.exports = function promise(stream) {\n  stream = stream || this;\n  return new Promise(function(resolve, reject) {\n    var results = [];\n    stream\n      .on('data', function(result) {\n        results.push(result);\n      })\n      .on('end', function() {\n        resolve(Buffer.isBuffer(results[0]) ? Buffer.concat(results).toString() : results);\n      })\n      .on('error', reject);\n  });\n};\n","D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\speech-to-text\\content-type.js",["96"],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\lib\\util\\process-user-parameters.js",[],"D:\\Lab\\speech-to-text-electron\\electron-react-app\\src\\components\\ModelDropdown.js",[],{"ruleId":"97","replacedBy":"98"},{"ruleId":"99","replacedBy":"100"},{"ruleId":"101","severity":1,"message":"102","line":2,"column":8,"nodeType":"103","messageId":"104","endLine":2,"endColumn":12},{"ruleId":"97","replacedBy":"105"},{"ruleId":"99","replacedBy":"106"},{"ruleId":"107","severity":1,"message":"108","line":17,"column":1,"nodeType":"109","messageId":"110","endLine":17,"endColumn":14,"fix":"111"},{"ruleId":"107","severity":1,"message":"108","line":17,"column":1,"nodeType":"109","messageId":"110","endLine":17,"endColumn":14,"fix":"112"},{"ruleId":"101","severity":1,"message":"113","line":159,"column":7,"nodeType":"103","messageId":"104","endLine":159,"endColumn":18},{"ruleId":"114","severity":1,"message":"115","line":161,"column":125,"nodeType":"116","messageId":"117","endLine":161,"endColumn":126},{"ruleId":"107","severity":1,"message":"108","line":17,"column":1,"nodeType":"109","messageId":"110","endLine":17,"endColumn":14,"fix":"118"},{"ruleId":"97","replacedBy":"119"},{"ruleId":"99","replacedBy":"120"},{"ruleId":"107","severity":1,"message":"108","line":1,"column":1,"nodeType":"109","messageId":"110","endLine":1,"endColumn":14,"fix":"121"},{"ruleId":"97","replacedBy":"122"},{"ruleId":"99","replacedBy":"123"},{"ruleId":"107","severity":1,"message":"108","line":17,"column":1,"nodeType":"109","messageId":"110","endLine":17,"endColumn":14,"fix":"124"},{"ruleId":"107","severity":1,"message":"108","line":1,"column":1,"nodeType":"109","messageId":"110","endLine":1,"endColumn":14,"fix":"125"},{"ruleId":"107","severity":1,"message":"108","line":1,"column":1,"nodeType":"109","messageId":"110","endLine":1,"endColumn":14,"fix":"126"},{"ruleId":"107","severity":1,"message":"108","line":1,"column":1,"nodeType":"109","messageId":"110","endLine":1,"endColumn":14,"fix":"127"},{"ruleId":"97","replacedBy":"128"},{"ruleId":"99","replacedBy":"129"},{"ruleId":"107","severity":1,"message":"108","line":1,"column":1,"nodeType":"109","messageId":"110","endLine":1,"endColumn":14,"fix":"130"},{"ruleId":"107","severity":1,"message":"108","line":1,"column":1,"nodeType":"109","messageId":"110","endLine":1,"endColumn":14,"fix":"131"},"no-native-reassign",["132"],"no-negated-in-lhs",["133"],"no-unused-vars","'logo' is defined but never used.","Identifier","unusedVar",["132"],["133"],"strict","'use strict' is unnecessary inside of modules.","ExpressionStatement","module",{"range":"134","text":"135"},{"range":"136","text":"135"},"'queryString' is assigned a value but never used.","no-useless-concat","Unexpected string concatenation of literals.","BinaryExpression","unexpectedConcat",{"range":"137","text":"135"},["132"],["133"],{"range":"138","text":"135"},["132"],["133"],{"range":"139","text":"135"},{"range":"140","text":"135"},{"range":"141","text":"135"},{"range":"142","text":"135"},["132"],["133"],{"range":"143","text":"135"},{"range":"144","text":"135"},"no-global-assign","no-unsafe-negation",[617,630],"",[617,630],[617,630],[0,13],[617,630],[0,13],[0,13],[0,13],[0,13],[0,13]]